<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://www.briglamoreaux.com/tag/hadoop/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://www.briglamoreaux.com/" rel="alternate" type="text/html" />
  <updated>2023-03-15T00:27:36+00:00</updated>
  <id>https://www.briglamoreaux.com/tag/hadoop/feed.xml</id>

  
  
  

  
    <title type="html">Brig Lamoreaux | </title>
  

  
    <subtitle>Long term storage for a forgetful mind</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">How Long to Deploy a Secure HDInsight Cluster</title>
      <link href="https://www.briglamoreaux.com/2017/08/23/how-long-to-deploy-a-secure-hdinsight-cluster.html" rel="alternate" type="text/html" title="How Long to Deploy a Secure HDInsight Cluster" />
      <published>2017-08-23T00:00:00+00:00</published>
      <updated>2017-08-23T00:00:00+00:00</updated>
      <id>https://www.briglamoreaux.com/2017/08/23/how-long-to-deploy-a-secure-hdinsight-cluster</id>
      <content type="html" xml:base="https://www.briglamoreaux.com/2017/08/23/how-long-to-deploy-a-secure-hdinsight-cluster.html">&lt;p&gt;It takes a while to build a secure HDInsight cluster. In my case it was about an hour from start to finish.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.briglamoreaux.com/assets/images/secureclusterdeployment.jpg&quot; alt=&quot;SecureClusterDeployment&quot; /&gt;&lt;/p&gt;

&lt;p&gt;About half of the work was setting up the VNet and configuring the Domain Controllers. The HDInsight cluster took about 30 mins which his about normal.&lt;/p&gt;

&lt;p&gt;Some steps were dependent on other steps and also some steps were running asynchronously. I didn’t record when I started the process, so I’m using the time of the first time as my zero. Add a few seconds on for the first step to run.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Deployment step&lt;/th&gt;
      &lt;th&gt;Time from Start (min)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Availability Set&lt;/td&gt;
      &lt;td&gt;00.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Public IP&lt;/td&gt;
      &lt;td&gt;00.08&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Load Balancer&lt;/td&gt;
      &lt;td&gt;00.11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;VNet&lt;/td&gt;
      &lt;td&gt;00.26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;BDC Nic&lt;/td&gt;
      &lt;td&gt;00.29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PDC Nic&lt;/td&gt;
      &lt;td&gt;00.31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Storage Account&lt;/td&gt;
      &lt;td&gt;00.31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AD BDC VM&lt;/td&gt;
      &lt;td&gt;05.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AD PDC VM&lt;/td&gt;
      &lt;td&gt;05.70&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prepare BDC Script&lt;/td&gt;
      &lt;td&gt;12.80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Create AD Forest Script&lt;/td&gt;
      &lt;td&gt;23.90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Update Vnet DNS1 Script&lt;/td&gt;
      &lt;td&gt;24.10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Update BDC Nic Script&lt;/td&gt;
      &lt;td&gt;24.90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Configure BDC Script&lt;/td&gt;
      &lt;td&gt;29.70&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Update Vnet DNS2 Script&lt;/td&gt;
      &lt;td&gt;29.90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Create Cluster&lt;/td&gt;
      &lt;td&gt;56.00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content>

      
      
      
      
      

      <author>
          <name>Brig Lamoreaux</name>
        
        
      </author>

      

      
        <category term="hadoop" />
      
        <category term="hdinsight" />
      

      
        <summary type="html">It takes a while to build a secure HDInsight cluster. In my case it was about an hour from start to finish.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Here are the differences between HDInsight and Hortonworks HDP</title>
      <link href="https://www.briglamoreaux.com/2017/05/08/here-are-the-differences-between-hdinsight-and-hortonworks-hdp.html" rel="alternate" type="text/html" title="Here are the differences between HDInsight and Hortonworks HDP" />
      <published>2017-05-08T00:00:00+00:00</published>
      <updated>2017-05-08T00:00:00+00:00</updated>
      <id>https://www.briglamoreaux.com/2017/05/08/here-are-the-differences-between-hdinsight-and-hortonworks-hdp</id>
      <content type="html" xml:base="https://www.briglamoreaux.com/2017/05/08/here-are-the-differences-between-hdinsight-and-hortonworks-hdp.html">&lt;p&gt;I get asked a lot about the differences between Microsoft HDInsight and Hortonworks HDP. Turns out there tight coordinated development efforts between the two companies. I was surprised to see how much closer the two products are now today compared to a year ago. Here is what I was able to find.&lt;/p&gt;

&lt;h2 id=&quot;lag-in-versions&quot;&gt;Lag in Versions&lt;/h2&gt;

&lt;p&gt;As of today, 8 May 2017, the current versions are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HDP: 2.6&lt;/li&gt;
  &lt;li&gt;HDInsight: 3.5. Based on HDP 2.5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, the first thing we see is HDInsight has a lag between the latest and greatest of Hortonworks. This really results in differences between feature version. That makes sense because Azure is a different beast than a straight IaaS deployments. Microsoft engineers need to make it work with WASB storage and other Azure specific architecture (networking, security, etc).&lt;/p&gt;

&lt;h2 id=&quot;feature-gaps&quot;&gt;Feature Gaps&lt;/h2&gt;

&lt;p&gt;It would be great if all of the features were ported to Azure but they are not. Some priorities are made on what to support. I imagine this is driven by customer demand. Here are the feature not found in HDInsight:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Druid&lt;/li&gt;
  &lt;li&gt;Solr&lt;/li&gt;
  &lt;li&gt;Slider&lt;/li&gt;
  &lt;li&gt;Accumulo&lt;/li&gt;
  &lt;li&gt;Falcon&lt;/li&gt;
  &lt;li&gt;Atlas&lt;/li&gt;
  &lt;li&gt;Flume&lt;/li&gt;
  &lt;li&gt;Knox&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;I found this information from the product pages&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HDP tools found in HDInsight &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning&quot;&gt;https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-component-versioning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Apache tools found in HDP &lt;a href=&quot;https://hortonworks.com/products/data-center/hdp/&quot;&gt;https://hortonworks.com/products/data-center/hdp/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/datasheet/microsoft-azure-hdinsight/&quot;&gt;https://hortonworks.com/datasheet/microsoft-azure-hdinsight/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Brig Lamoreaux</name>
        
        
      </author>

      

      
        <category term="software" />
      
        <category term="azure" />
      
        <category term="hadoop" />
      
        <category term="hdinsight" />
      
        <category term="hdp" />
      

      
        <summary type="html">I get asked a lot about the differences between Microsoft HDInsight and Hortonworks HDP. Turns out there tight coordinated development efforts between the two companies. I was surprised to see how much closer the two products are now today compared to a year ago. Here is what I was able to find.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Installing Hadoop Cluster</title>
      <link href="https://www.briglamoreaux.com/2010/12/08/installing-hadoop-cluster.html" rel="alternate" type="text/html" title="Installing Hadoop Cluster" />
      <published>2010-12-08T00:00:00+00:00</published>
      <updated>2010-12-08T00:00:00+00:00</updated>
      <id>https://www.briglamoreaux.com/2010/12/08/installing-hadoop-cluster</id>
      <content type="html" xml:base="https://www.briglamoreaux.com/2010/12/08/installing-hadoop-cluster.html">&lt;p&gt;I have four VM machines in dev and I want to configure my own &lt;a href=&quot;http://hadoop.apache.org&quot;&gt;hadoop&lt;/a&gt; cluster to use as a tool and analysis.&lt;/p&gt;

&lt;p&gt;I’m going to follow the general process out lined by &lt;a href=&quot;http://hadoop.apache.org/common/docs/current/cluster_setup.html&quot;&gt;hadoop’s instructions&lt;/a&gt; and &lt;a href=&quot;http://developer.yahoo.com/hadoop/tutorial/module7.html#config-small&quot;&gt;yahoo help&lt;/a&gt;, &lt;a href=&quot;http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;this-is-what-the-final-setup-will-look-like&quot;&gt;This is what the final setup will look like&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://www.briglamoreaux.com/assets/images/hadoopcluster-dev2.png&quot; alt=&quot;HadoopCluster-Dev&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;prework&quot;&gt;Prework&lt;/h2&gt;

&lt;p&gt;I found that hadoop has &lt;a href=&quot;http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/&quot;&gt;default ports&lt;/a&gt; that need to be opened between servers before it will work.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Add local ssh support on each machine &lt;/span&gt;
ssh-keygen &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; dsa &lt;span class=&quot;nt&quot;&gt;-P&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ~/.ssh/id_dsa 
&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; ~/.ssh/id_dsa.pub &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.ssh/authorized_keys

&lt;span class=&quot;c&quot;&gt;# Configure master to talk to each slave.&lt;/span&gt;
a.brlamore@master:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh-copy-id &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.ssh/id_rsa.pub a.brlamore@slave 

&lt;span class=&quot;c&quot;&gt;# Configure each slave to talk to the master.&lt;/span&gt;
a.brlamore@slave:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh-copy-id &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.ssh/id_rsa.pub a.brlamore@master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;important-directories&quot;&gt;Important Directories&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Directory&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Suggested location&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;HADOOP_LOG_DIR&lt;/td&gt;
      &lt;td&gt;Output location for log files from daemons&lt;/td&gt;
      &lt;td&gt;/var/log/hadoop&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;hadoop.tmp.dir&lt;/td&gt;
      &lt;td&gt;A base for other temporary directories&lt;/td&gt;
      &lt;td&gt;/tmp/hadoop&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;dfs.name.dir&lt;/td&gt;
      &lt;td&gt;Where the NameNode metadata should be stored&lt;/td&gt;
      &lt;td&gt;/home/hadoop/dfs/name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;dfs.data.dir&lt;/td&gt;
      &lt;td&gt;Where DataNodes store their blocks&lt;/td&gt;
      &lt;td&gt;/home/hadoop/dfs/data&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mapred.system.dir&lt;/td&gt;
      &lt;td&gt;The in-HDFS path to shared MapReduce system files&lt;/td&gt;
      &lt;td&gt;/hadoop/mapred/system&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Hadoop Home&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HADOOP_HOME&lt;/code&gt; is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/u01/accts/a.brlamore/tmp/hadoop-0.21.0&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;I’ve put in a request for root access so I can change this to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/hadoop&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Edit Slaves file&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi /conf/slaves

ali-graph002.devapollogrp.edu 
ali-graph003.devapollogrp.edu 
ali-graph004.devapollogrp.edu 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Site Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Set the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JAVA_HOME&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/hadoop-env.sh&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export JAVA_HOME=/usr/java/default&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Set values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/core-site.xml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/u01/accts/a.brlamore/tmp/hadoop-datastore/hadoop-${user.name}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;A base for other temporary directories. Default location /tmp/hadoop-${user.name}. Suggested Location /tmp/hadoop&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.default.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://ali-graph001.devapollogrp.edu:8020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;The name of the default file system. This specifies the NameNode&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Set values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!--
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/u01/accts/a.brlamore/tmp/path/to/namenode/namesapce/&amp;lt;/value&amp;gt;
&amp;lt;description&amp;gt;Where the NameNode metadata should be stored. Default location is ${hadoop.tmp.dir}/dfs/name. Suggested location /home/hadoop/dfs/name&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/u01/accts/a.brlamore/tmp/path/to/datanode/namesapce/&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;Where DataNodes store their blocks. Default location ${hadoop.tmp.dir}/dfs/data. Suggested location /home/hadoop/dfs/data&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Set values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobtracker.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;ali-graph001.devapollogrp.edu:8021&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Host or IP and port of JobTracker&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Hadoop Startup&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Format the filesystem&lt;/span&gt;
bin/hadoop namenode &lt;span class=&quot;nt&quot;&gt;-format&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Start the HDFS on the NameNode&lt;/span&gt;
bin/start-dfs.sh

&lt;span class=&quot;c&quot;&gt;# Start Map-Reduce on the TrackerNode&lt;/span&gt;
bin/start-mapred.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content>

      
      
      
      
      

      <author>
          <name>Brig Lamoreaux</name>
        
        
      </author>

      

      
        <category term="hadoop" />
      

      
        <summary type="html">I have four VM machines in dev and I want to configure my own hadoop cluster to use as a tool and analysis.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">My Hadoop Training</title>
      <link href="https://www.briglamoreaux.com/2010/06/16/my-hadoop-training.html" rel="alternate" type="text/html" title="My Hadoop Training" />
      <published>2010-06-16T00:00:00+00:00</published>
      <updated>2010-06-16T00:00:00+00:00</updated>
      <id>https://www.briglamoreaux.com/2010/06/16/my-hadoop-training</id>
      <content type="html" xml:base="https://www.briglamoreaux.com/2010/06/16/my-hadoop-training.html">&lt;p&gt;Hadoop has been difficult getting into. I just don’t have enough linux/java training to help with understanding some of the foundational concepts. However, today I learned some valuable information.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;hadoop is a umbrella project for serveral other things (hdfs, mapreduce)&lt;/li&gt;
  &lt;li&gt;The program hadoop give me access to hdfs&lt;/li&gt;
  &lt;li&gt;I can use the FSShell (&amp;gt;hadoop fs -ls)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The next step is to now create my own hadoop map/reduce program.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Brig Lamoreaux</name>
        
        
      </author>

      

      
        <category term="hadoop" />
      

      
        <summary type="html">Hadoop has been difficult getting into. I just don’t have enough linux/java training to help with understanding some of the foundational concepts. However, today I learned some valuable information.</summary>
      

      
      
    </entry>
  
</feed>
